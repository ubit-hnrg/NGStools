{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyensembl import EnsemblRelease as ensbl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseArgs(description = 'Get coverage at different DPs for a given list of genes.'):\n",
    "    parser = argparse.ArgumentParser(description= description)\n",
    "    parser.add_argument('-b','--bamfile',required=True,help='input bam file')\n",
    "    parser.add_argument('-g','--genelistfile',required=True)\n",
    "    parser.add_argument('-o','--outpath',required=True)\n",
    "    parser.add_argument('-r','--ref',dest = 'ref',default = '',required = True,type=int,help = 'Reference genome is mandatory since only a list of genames is given and we need to match it inside our bam file')\n",
    "    parser.add_argument('-v','--vcffile',default = '',required=False,help='input vcf file to be usde for complementary analysis', )\n",
    "    parser.add_argument('-p','--prefix',dest = 'prefix',default = '',required = False)\n",
    "    parser.add_argument('-s','--splitBamFile', dest='split', action='store_false',help = 'in next iterations this flag will allow to split the reducedBAM file by chromosomes')\n",
    "    parser.set_defaults(split=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # MANDATORY ARGUMENTS\n",
    "    bamfile = args.bamfile\n",
    "    vcffile = args.vcffile\n",
    "    outpath = args.outpath\n",
    "    prefix = args.prefix\n",
    "    ref = args.ref\n",
    "    genelistfile = args.genelistfile\n",
    "    \n",
    "    #OPTIONAL ARGUMENTS\n",
    "    split= args.split\n",
    "    \n",
    "    return bamfile, vcffile, outpath, prefix, ref, genelistfile, split\n",
    "    \n",
    "    \n",
    "    \n",
    "def check_ref(ref,outpath):\n",
    "    if ref not in [19,37,38]:\n",
    "        print 'please, reference must be one of 19,37,38\\n'\n",
    "        print 'bye'\n",
    "        quit()\n",
    "    else:\n",
    "        if ref == 19:\n",
    "            print 'using ref hg19, '\n",
    "        if ref == 37:\n",
    "            print 'using ref hgrc37'\n",
    "        if ref == 38:\n",
    "            print 'using ref hgrc38'\n",
    "    print ''\n",
    "    \n",
    "    if not os.path.isdir(outpath):\n",
    "        os.system('mkdir %s'%outpath)    \n",
    "\n",
    "    \n",
    "    \n",
    "def get_genelist(genelistfile):\n",
    "    genes = pd.read_csv(genelistfile,header = None)\n",
    "    genelist = genes.iloc[:,0].tolist()\n",
    "    print 'genes read from file:'\n",
    "    print genelist\n",
    "    print '\\n'\n",
    "\n",
    "    return genelist\n",
    "    \n",
    "    \n",
    "def test_mode():\n",
    "    ref = 37\n",
    "    genelistfile = './test/genelist'\n",
    "    bamfile = './test/test_chr2_190-192k.bam'\n",
    "    outpath = './test_output/'\n",
    "    split = False\n",
    "    return(ref,genelistfile,bamfile,outpath,split)\n",
    "    \n",
    "    \n",
    "def get_locis(genelist,ref,outpath,write_bedfile = True):\n",
    "    analyzed_genes = []\n",
    "    try:\n",
    "        if (ref == 37)|(ref == 19):\n",
    "            ensemble_version = 75\n",
    "    except:\n",
    "        'You must to install the ensemble version 75, please run \\n'        \n",
    "        'pyensembl install --release 75 --species homo_sapiens \\n'\n",
    "    try:\n",
    "        if ref == 38:\n",
    "            ensemble_version = 87\n",
    "    except:\n",
    "        'You must to install latest ensemble version (87), please run \\n'        \n",
    "        'pyensembl install --release 87 --species homo_sapiens \\n'\n",
    "        \n",
    "    data = ensbl(ensemble_version)\n",
    "    locis = []\n",
    "\n",
    "    for gen in genelist:\n",
    "        try:\n",
    "            loc =  data.loci_of_gene_names(gen)\n",
    "            locis.append(loc[0].to_dict())\n",
    "            analyzed_genes.append(gen)\n",
    "        except:\n",
    "            print 'warning, gen %s was not found and ignored'%gen\n",
    "#    return pd.concat(locis)\n",
    "    print '\\n'\n",
    "    ggenes = analyzed_genes\n",
    "    locis = pd.DataFrame(locis)\n",
    "    locis['name'] = ggenes\n",
    "    locis.rename(columns = {'contig':'chrom'},inplace = True)\n",
    "    locis['score'] = 0 ## this is only for completness, in order to recognize strand as the right next field\n",
    "    locis = locis[['chrom','start','end','name','score','strand']]\n",
    "    \n",
    "    # write file\n",
    "    bedfile = outpath+'gene_loci.bed'\n",
    "    if write_bedfile:\n",
    "        locis.to_csv(bedfile,sep = '\\t',index = False,header = None)\n",
    "        \n",
    "    return locis, bedfile, locis.columns\n",
    "\n",
    "\n",
    "def run_samtools_view(bamfile,bedfile,split=False):\n",
    "    base = os.path.basename(bamfile).split('.bam')[0]\n",
    "    #print base\n",
    "    outbam = outpath + base + '_reduced.bam'\n",
    "    if not split:\n",
    "        bedfile = bedfile\n",
    "        call1 = 'samtools view -bh -L %s %s > %s'%(bedfile,bamfile,outbam)\n",
    "        #print call1\n",
    "    status = os.system(call1)    \n",
    "    if status ==0:\n",
    "        print 'ok samtools'\n",
    "    else:\n",
    "        print 'samtools have failed'\n",
    "        #quit()\n",
    "\n",
    "    # get index\n",
    "    call2 = 'samtools index %s'%(outbam)\n",
    "    index = os.system(call2)\n",
    "    if index ==0:\n",
    "        print 'ok index'\n",
    "    else:\n",
    "        print 'index have failed'\n",
    "        #quit()\n",
    "\n",
    "    return  outbam\n",
    "    \n",
    "#def clean_files(): \n",
    "#    rm \n",
    "\n",
    "def serie_counting(x):\n",
    "    return pd.Series({'bp_at_10dp':(x>10).sum(),'bp_at_20dp':(x>20).sum(),'bp_at_30dp':(x>30).sum()})\n",
    "\n",
    "def run_bedtools_coverage(bam,bed,outpath,exonbed = False):\n",
    "    \n",
    "    outcoveragefile = outpath +os.path.basename(bed)+'.tsv'\n",
    "    exon_file_report= outpath +os.path.basename(bed)+'_exon_report'+'.tsv'\n",
    "    print outcoveragefile\n",
    "    call = 'coverageBed -a %s -b %s > %s'%(bed,bam,outcoveragefile)\n",
    "    status = os.system(call)\n",
    "    #print call\n",
    "    if status ==0:\n",
    "        print 'ok coveragedBed'\n",
    "    else:\n",
    "        print 'coveragedBed have failed'\n",
    "\n",
    "    results = pd.read_table(outcoveragefile,header = None)\n",
    "    results.columns = ['chr','start','end','name','score','strand','matched_reads','coverage_dp1','len_gen_bp','rel_coverage_dp1']\n",
    "        \n",
    "    \n",
    "    ### the later approach give us the coverage as the \n",
    "    #number of read bases at least ONE time over the total length of our gene of interest\n",
    "    \n",
    "    ## in the following I atempt to compute the coverage at different minimal dp levels, namely: at dp= 10, 20, 30\n",
    "    \n",
    "    #compute dp per base x gene\n",
    "    file_by_position = outpath + 'coverage_by_position.txt'\n",
    "    call2 = 'coverageBed -a %s -b %s -d > %s'%(bed,bam,file_by_position)\n",
    "    os.system(call2)\n",
    "    \n",
    "    bypos = pd.read_csv(file_by_position,sep = '\\t',header = None)\n",
    "    #print bypos.head()\n",
    "    grouping = bypos.groupby([3])[7].apply(lambda x: serie_counting(x))\n",
    "    \n",
    "    res  = grouping.unstack(); \n",
    "    #reset index and rename it\n",
    "    cols = res.columns  #reserve columns\n",
    "    res.reset_index(inplace = True)\n",
    "    res.columns = ['name']+list(cols)\n",
    "\n",
    "    \n",
    "    ###  merge both analysis\n",
    "    coverage = pd.merge(results,res, on = 'name')\n",
    "    \n",
    "    ### relativise results\n",
    "    abscols = ['bp_at_10dp','bp_at_20dp','bp_at_30dp']\n",
    "\n",
    "    \n",
    "    if not exonbed:\n",
    "        relatives = np.round((coverage[abscols].transpose() /coverage['len_gen_bp'].values).transpose(),7)\n",
    "        coverage[abscols] = relatives\n",
    "    coverage.to_csv(outcoveragefile,index = False, sep = '\\t')\n",
    "\n",
    "    if exonbed:    \n",
    "        exome_report = coverage.groupby(['score'])[['coverage_dp1','len_gen_bp','bp_at_10dp','bp_at_20dp','bp_at_30dp']].sum()\n",
    "        rel = exome_report.apply(lambda x:x/float(x['len_gen_bp']),axis = 1).drop([u'len_gen_bp'],axis = 1)\n",
    "        exon_coverage = exome_report[['len_gen_bp']].join(rel)\n",
    "        exon_coverage.reset_index(inplace = True)\n",
    "        exon_coverage.rename(columns = {'score':'name'},inplace = True)\n",
    "        exon_coverage.to_csv(exon_file_report,index =False , sep = '\\t')\n",
    "\n",
    "    \n",
    "    \n",
    "    return outcoveragefile\n",
    "\n",
    "\n",
    "def get_exons(genelist,ref,outpath,write_bedfile = True):\n",
    "    analyzed_genes = []\n",
    "    try:\n",
    "        if (ref == 37)|(ref == 19):\n",
    "            ensemble_version = 75\n",
    "    except:\n",
    "        'You must to install the ensemble version 75, please run \\n'        \n",
    "        'pyensembl install --release 75 --species homo_sapiens \\n'\n",
    "    try:\n",
    "        if ref == 38:\n",
    "            ensemble_version = 87\n",
    "    except:\n",
    "        'You must to install latest ensemble version (87), please run \\n'        \n",
    "        'pyensembl install --release 87 --species homo_sapiens \\n'\n",
    "        \n",
    "    data = ensbl(ensemble_version)\n",
    "    ############ By Exons #############\n",
    "    exonbed = []\n",
    "    for gene in genelist:\n",
    "        try:\n",
    "            exons = data.exon_ids_of_gene_name(gene)\n",
    "            exonLocus = [data.locus_of_exon_id(e) for e in exons]\n",
    "            exonLoci = [ex.to_dict() for ex in exonLocus]\n",
    "            exonLoci = pd.DataFrame(exonLoci)\n",
    "            exonLoci['name'] = exons\n",
    "            exonLoci['score'] = [gene]*len(exons)\n",
    "            exonLoci.rename(columns = {'contig':'chrom'},inplace = True)\n",
    "            #exonLoci['score'] = 0 ## this is only for completness, in order to recognize strand as the right next field\n",
    "            exonLoci = exonLoci[['chrom','start','end','name','score','strand']]\n",
    "            exonbed.append(exonLoci)\n",
    "            analyzed_genes.append(gene)\n",
    "        except:\n",
    "            print 'warning, gene %s was not found and ignored'%gene\n",
    "\n",
    "    print '\\n'\n",
    "    exonbed = pd.concat(exonbed)\n",
    "    \n",
    "    # write file\n",
    "    exonbedfile = outpath+'exons_loci.bed'\n",
    "\n",
    "    if write_bedfile:\n",
    "        exonbed.to_csv(exonbedfile,sep = '\\t',index = False,header = None)\n",
    "    \n",
    "        \n",
    "    return exonbed, exonbedfile, exonbed.columns\n",
    "\n",
    "def main(test = True):\n",
    "    if test:\n",
    "        ref, genelistfile, bamfile, outpath, split = test_mode()\n",
    "    else:\n",
    "        bamfile, vcffile, outpath, prefix, ref, genelistfile, split = parseArgs()\n",
    "    #check params\n",
    "    check_ref(ref=ref,outpath = outpath)\n",
    "\n",
    "    genelist = get_genelist(genelistfile)\n",
    "    gene_loci , bedfile , locicolumns = get_locis(genelist,ref = ref,outpath=outpath)\n",
    "    exon_loci , exon_bedfile , exon_columns = get_exons(genelist,ref = ref,outpath=outpath)\n",
    "\n",
    "    \n",
    "    reduced_bamfile = run_samtools_view(bamfile,bedfile,split=split)\n",
    "    \n",
    "    #compute coverage by gen along the bamfile\n",
    "    coverage_file = run_bedtools_coverage(reduced_bamfile,bedfile,outpath)\n",
    "    coverage_by_exon = run_bedtools_coverage(reduced_bamfile,exon_bedfile,outpath,exonbed= True)\n",
    "    \n",
    "    \n",
    "    exome_coverage = pd.read_table(coverage_by_exon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
